{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57882a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from scipy.spatial import distance \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Each Predicted car position sheet (16 Features) fill nans with 0 Pad to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_folder = 'CSVsPred'\n",
    "csvs_attackers = glob.glob('{}/*_attacker.csv'.format(start_folder))\n",
    "df_attackers = []\n",
    "\n",
    "for c in csvs_attackers:\n",
    "    df = pd.read_csv(c).drop(['Unnamed: 0','Unnamed: 0.1', 'time', 'sender', 'attackerType'], axis=1).fillna(0)\n",
    "\n",
    "    df = np.asarray(df).astype('float32')\n",
    "    df = np.pad(df, ((0,100-df.shape[0]),(0,0)), 'constant')\n",
    "    if df.shape[1] == 16:\n",
    "\n",
    "        df_attackers.append(df)\n",
    "    \n",
    "print(len(df_attackers))\n",
    "df_attackers = np.asarray(df_attackers)\n",
    "np.save('CSVsPred/np_attackers_pred.npy', df_attackers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14312\n"
     ]
    }
   ],
   "source": [
    "start_folder = 'CSVsPred'\n",
    "csvs_normal = glob.glob('{}/*_normal.csv'.format(start_folder))\n",
    "df_normal = []\n",
    "\n",
    "for c in csvs_normal:\n",
    "    df = pd.read_csv(c).drop(['Unnamed: 0','Unnamed: 0.1', 'time', 'sender', 'attackerType'], axis=1).fillna(0)\n",
    "\n",
    "    df = np.asarray(df).astype('float32')\n",
    "    df = np.pad(df, ((0,100-df.shape[0]),(0,0)), 'constant')\n",
    "    if df.shape[1] == 16:\n",
    "        df_normal.append(df)\n",
    "    \n",
    "print(len(df_normal))\n",
    "# df_normal = np.asarray(df_normal)\n",
    "df_normal = np.asarray(df_normal)\n",
    "np.save('CSVsPred/np_normal_pred.npy', df_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2fd00",
   "metadata": {},
   "source": [
    "# Loads each whole scenario as a sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf5902",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_folder = 'AllCSVs'\n",
    "csvs_scen = glob.glob(r'{}\\*.csv'.format(start_folder))\n",
    "df_scen = []\n",
    "\n",
    "for c in csvs_scen:\n",
    "    df = pd.read_csv(c).drop(['type','messageID','spd_noise0','spd_noise1','spd_noise2' ,'pos_noise0' ,'pos_noise1' ,'pos_noise2', 'spd2', 'pos2'], axis=1)\n",
    "    df_scen.append(df)\n",
    "print(len(df_scen))\n",
    "df_scen[0][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_scen:\n",
    "    scaler = StandardScaler()\n",
    "    df[['pos0', 'pos1']] = scaler.fit_transform(df[['pos0', 'pos1']])\n",
    "    df[['spd0', 'spd1']] = scaler.fit_transform(df[['spd0', 'spd1']])\n",
    "df_scen[2][0:100]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a79e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb1a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find the two closest rows above a given row based on A and B values\n",
    "def find_closest_rows_above(df, row):\n",
    "    # select a row to find closest rows to\n",
    "    given_row = row\n",
    "\n",
    "    # Find the index of the given row\n",
    "    row_index = df.index.get_loc(given_row.name)\n",
    "\n",
    "    # Slice the DataFrame to only consider rows above the given row\n",
    "    above_df = df.iloc[max(0, row_index-2000):row_index]\n",
    "\n",
    "    if len(above_df) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # select the A and B columns of the DataFrame\n",
    "    df_ab = above_df[['time', 'pos0', 'pos1']]\n",
    "\n",
    "    # calculate the Euclidean distance between the given row and all other rows based on A and B values\n",
    "    distances = distance.cdist(df_ab, [given_row[['time', 'pos0', 'pos1']]], metric='euclidean')\n",
    "\n",
    "    # get the indices of rows sorted by distance\n",
    "    sorted_indices = distances.argsort(axis=0).flatten()\n",
    "\n",
    "    # get the closest rows as a DataFrame\n",
    "    closest_rows = df.iloc[sorted_indices]\n",
    "    \n",
    "    # Create a Boolean mask to select the rows that contain the value. Ensures that senders are not the same\n",
    "    mask = closest_rows['sender'] == search_row.sender\n",
    "\n",
    "    # Drop the rows that match the mask\n",
    "    closest_rows.drop(closest_rows[mask].index, inplace=True)\n",
    "\n",
    "    return closest_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b6a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_closest = []\n",
    "p = 0\n",
    "for df in df_scen:\n",
    "    df_copy = df.copy()\n",
    "    for i in range(2, len(df_copy)): #len(df)\n",
    "#         print(i)\n",
    "#         display(search_row)\n",
    "        search_row = df_copy.iloc[i] \n",
    "        closest_rows = find_closest_rows_above(df.copy(), search_row).reset_index()\n",
    "        closest_car_nums = [0,1]\n",
    "        feats = ['pos0','pos1','spd0','spd1']\n",
    "#         display(closest_rows)\n",
    "        for num in closest_car_nums:\n",
    "            for f in feats:\n",
    "                df_copy.loc[i, f'{f}Close{num}'] = closest_rows.loc[num, f]\n",
    "    \n",
    "    df_copy.to_csv(r'C:\\Users\\aidan\\Desktop\\5G-BSM-Threat-Detection\\ScenarioScaled\\scenario_{}.csv'.format(p))  \n",
    "    df_closest.append(df_copy)\n",
    "    p+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b2e38",
   "metadata": {},
   "source": [
    "# ----------------------------------------Make Numpy-----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Step **Chop out the first 2 rows of the df**\n",
    "start_folder = 'ScenarioScaled'#'ClosestCarCSVsModel2'\n",
    "csvs = glob.glob(r'{}\\*.csv'.format(start_folder))\n",
    "df_list = []\n",
    "\n",
    "for c in csvs:\n",
    "    df = pd.read_csv(c)\n",
    "    for i in np.unique(df.sender):\n",
    "        df_list.append(df[df.sender.isin([i])].copy())\n",
    "    #     df[df.ID.isin([subs[0]])&df.Vigil.isin(vigils[0])].copy()\n",
    "print(len(df_list))\n",
    "# df_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ca671",
   "metadata": {},
   "source": [
    "# BSM Length 10 (Windowed, Slide 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599976d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_attacker = []\n",
    "df_normal = []\n",
    "window_size = 20\n",
    "overlap_size = 19\n",
    "df = df_list[0:10]\n",
    "for j in df:\n",
    "#     print(j)\n",
    "    if j.attackerType.any() == 0:\n",
    "        j = j.iloc[:,4:].fillna(0)#4\n",
    "        for start_idx in range(0, len(j)-window_size, window_size - overlap_size):\n",
    "            end_idx = start_idx + window_size\n",
    "            df_temp = j.iloc[start_idx:end_idx]\n",
    "#             display(df_chunk)\n",
    "            scaler = StandardScaler()\n",
    "            df_temp[['pos0', 'pos1']] = scaler.fit_transform(df_temp[['pos0', 'pos1']])\n",
    "            df_temp[['spd0', 'spd1']] = scaler.fit_transform(df_temp[['spd0', 'spd1']])\n",
    "            df_temp[['pos0Close0', 'pos1Close0']] = scaler.fit_transform(df_temp[['pos0Close0', 'pos1Close0']])\n",
    "            df_temp[['spd0Close0', 'spd1Close0']] = scaler.fit_transform(df_temp[['spd0Close0', 'spd1Close0']])\n",
    "            df_temp[['pos0Close1', 'pos1Close1']] = scaler.fit_transform(df_temp[['pos0Close1', 'pos1Close1']])\n",
    "            df_temp[['spd0Close1', 'spd1Close1']] = scaler.fit_transform(df_temp[['spd0Close1', 'spd1Close1']])\n",
    "            \n",
    "            df_normal.append(df_temp)\n",
    "        \n",
    "    \n",
    "    elif j.attackerType.any() == 1:\n",
    "        j = j.iloc[:,4:].fillna(0)\n",
    "        for start_idx in range(0, len(j)-window_size, window_size - overlap_size):\n",
    "            end_idx = start_idx + window_size\n",
    "            df_temp = j.iloc[start_idx:end_idx]\n",
    "#             display(df_chunk)\n",
    "            scaler = StandardScaler()\n",
    "            df_temp[['pos0', 'pos1']] = scaler.fit_transform(df_temp[['pos0', 'pos1']])\n",
    "            df_temp[['spd0', 'spd1']] = scaler.fit_transform(df_temp[['spd0', 'spd1']])\n",
    "            df_temp[['pos0Close0', 'pos1Close0']] = scaler.fit_transform(df_temp[['pos0Close0', 'pos1Close0']])\n",
    "            df_temp[['spd0Close0', 'spd1Close0']] = scaler.fit_transform(df_temp[['spd0Close0', 'spd1Close0']])\n",
    "            df_temp[['pos0Close1', 'pos1Close1']] = scaler.fit_transform(df_temp[['pos0Close1', 'pos1Close1']])\n",
    "            df_temp[['spd0Close1', 'spd1Close1']] = scaler.fit_transform(df_temp[['spd0Close1', 'spd1Close1']])\n",
    "            \n",
    "            df_attacker.append(df_temp)\n",
    "        \n",
    "\n",
    "# df_normal = np.asarray(df_normal)\n",
    "# df_attacker = np.asarray(df_attacker)\n",
    "display(df_normal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d5e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = np.asarray(df_normal[0])\n",
    "\n",
    "flat.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239114d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal.shape, df_attacker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9df050",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'C:\\Users\\aidan\\Desktop\\5G-BSM-Threat-Detection\\ClosestCarCSVsModel2\\np_normal_len50.npy', df_normal)\n",
    "np.save(r'C:\\Users\\aidan\\Desktop\\5G-BSM-Threat-Detection\\ClosestCarCSVsModel2\\np_attacker_len50.npy', df_attacker)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db08240",
   "metadata": {},
   "source": [
    "# BSM Length 100 (Full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef62e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0].iloc[:,4:].fillna(0)\n",
    "df_temp = np.asarray(df_temp).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacker = []\n",
    "df_normal = []\n",
    "count = 0\n",
    "for j in df_list:\n",
    "#     print(j.attackerType)\n",
    "    if j.attackerType.any() == 0:       \n",
    "        df_temp = j.iloc[:,4:].fillna(0)\n",
    "        df_temp = np.asarray(df_temp).astype('float32')\n",
    "        j = np.pad(df_temp, ((0,100-j.shape[0]),(0,0)), 'constant')\n",
    "#         j = torch.tensor(j, dtype=torch.long)\n",
    "        df_normal.append(j.flatten())\n",
    "#         print(j.flatten().shape)\n",
    "    elif j.attackerType.any() == 1:\n",
    "        count+=1\n",
    "        df_temp = j.iloc[:,4:].fillna(0)\n",
    "        df_temp = np.asarray(df_temp).astype('float32')\n",
    "        j = np.pad(df_temp, ((0,100-j.shape[0]),(0,0)), 'constant')\n",
    "#         j = torch.tensor(j, dtype=torch.long)\n",
    "        df_attacker.append(j.flatten())\n",
    "\n",
    "        \n",
    "        \n",
    "# df_normal = torch.tensor(df_normal)\n",
    "# df_attacker = torch.tensor(df_attacker)\n",
    "# torch.save(df_normal, 'df_normal_allscaled.pt')\n",
    "# torch.save(df_attacker, 'df_attacker_allscaled.pt')\n",
    "\n",
    "df_normal = np.asarray(df_normal)\n",
    "df_attacker = np.asarray(df_attacker)\n",
    "\n",
    "df_normal.shape\n",
    "# np.save(r'C:\\Users\\aidan\\Desktop\\5G-BSM-Threat-Detection\\ScenarioScaled\\df_normal_allscaled_flat.npy', df_normal)\n",
    "# np.save(r'C:\\Users\\aidan\\Desktop\\5G-BSM-Threat-Detection\\ScenarioScaled\\df_attacker_allscaled_flat.npy', df_attacker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b721a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'C:\\Users\\aidan\\Desktop\\5G-BSM-Threat-Detection\\ScenarioScaled\\df_normal_allscaled_flat.npy', df_normal)\n",
    "np.save(r'C:\\Users\\aidan\\Desktop\\5G-BSM-Threat-Detection\\ScenarioScaled\\df_attacker_allscaled_flat.npy', df_attacker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045ddb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a51c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacker = []\n",
    "df_normal = []\n",
    "count = 0\n",
    "for j in df_list:\n",
    "#     print(j.attackerType)\n",
    "    if j.attackerType.any() == 0:       \n",
    "        df_temp = j.iloc[:,4:].fillna(0)\n",
    "        scaler = StandardScaler()\n",
    "        df_temp[['pos0', 'pos1']] = scaler.fit_transform(df_temp[['pos0', 'pos1']])\n",
    "        df_temp[['spd0', 'spd1']] = scaler.fit_transform(df_temp[['spd0', 'spd1']])\n",
    "        df_temp[['pos0Close0', 'pos1Close0']] = scaler.fit_transform(df_temp[['pos0Close0', 'pos1Close0']])\n",
    "        df_temp[['spd0Close0', 'spd1Close0']] = scaler.fit_transform(df_temp[['spd0Close0', 'spd1Close0']])\n",
    "        df_temp[['pos0Close1', 'pos1Close1']] = scaler.fit_transform(df_temp[['pos0Close1', 'pos1Close1']])\n",
    "        df_temp[['spd0Close1', 'spd1Close1']] = scaler.fit_transform(df_temp[['spd0Close1', 'spd1Close1']])\n",
    "#         display(df_temp)\n",
    "        \n",
    "#         df_temp = np.asarray(df_temp).astype('float32')\n",
    "        j = np.pad(df_temp, ((0,100-j.shape[0]),(0,0)), 'constant')\n",
    "        j = torch.tensor(j, dtype=torch.long)\n",
    "        df_normal.append(j)\n",
    "#         print(np.asarray(j).shape)\n",
    "    elif j.attackerType.any() == 1:\n",
    "        count+=1\n",
    "        \n",
    "        df_temp = j.iloc[:,4:].fillna(0)\n",
    "        scaler = StandardScaler()\n",
    "        df_temp[['pos0', 'pos1']] = scaler.fit_transform(df_temp[['pos0', 'pos1']])\n",
    "        df_temp[['spd0', 'spd1']] = scaler.fit_transform(df_temp[['spd0', 'spd1']])\n",
    "        df_temp[['pos0Close0', 'pos1Close0']] = scaler.fit_transform(df_temp[['pos0Close0', 'pos1Close0']])\n",
    "        df_temp[['spd0Close0', 'spd1Close0']] = scaler.fit_transform(df_temp[['spd0Close0', 'spd1Close0']])\n",
    "        df_temp[['pos0Close1', 'pos1Close1']] = scaler.fit_transform(df_temp[['pos0Close1', 'pos1Close1']])\n",
    "        df_temp[['spd0Close1', 'spd1Close1']] = scaler.fit_transform(df_temp[['spd0Close1', 'spd1Close1']])\n",
    "\n",
    "#         df_temp = np.asarray(df_temp).astype('float32')\n",
    "        j = np.pad(df_temp, ((0,100-j.shape[0]),(0,0)), 'constant')\n",
    "        j = torch.tensor(j, dtype=torch.long)\n",
    "        df_attacker.append(j)\n",
    "\n",
    "        \n",
    "        \n",
    "# df_normal = torch.tensor(df_normal)\n",
    "# df_attacker = torch.tensor(df_attacker)\n",
    "# torch.save(df_normal, 'df_normal_allscaled.pt')\n",
    "# torch.save(df_attacker, 'df_attacker_allscaled.pt')\n",
    "\n",
    "df_normal = np.asarray(df_normal)\n",
    "df_attacker = np.asarray(df_attacker)\n",
    "\n",
    "df_normal.shape\n",
    "np.save(r'C:\\Users\\aidan\\Desktop\\5G-BSM-Threat-Detection\\ScenarioScaled\\df_normal_allscaled.npy', df_normal)\n",
    "np.save(r'C:\\Users\\aidan\\Desktop\\5G-BSM-Threat-Detection\\ScenarioScaled\\df_attacker_allscaled.npy', df_attacker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'C:\\Users\\aidan\\Desktop\\5G-BSM-Threat-Detection\\ClosestCarCSVsModel2\\np_normal.npy', df_normal)\n",
    "np.save(r'C:\\Users\\aidan\\Desktop\\5G-BSM-Threat-Detection\\ClosestCarCSVsModel2\\np_attacker.npy', df_attacker)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549d8ca6",
   "metadata": {},
   "source": [
    "# ------------------------------------------Template Code-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ed12ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 4,6,7,8,9],\n",
    "    'B': [2, 4, 6, 8, 7,3,7,3,8],\n",
    "    'C': [3, 6, 9, 12, 3,2,9,6,4]\n",
    "})\n",
    "\n",
    "# select a row to find closest rows to\n",
    "given_row = df.iloc[4]\n",
    "\n",
    "# Find the index of the given row\n",
    "row_index = df.index.get_loc(given_row.name)\n",
    "\n",
    "# Slice the DataFrame to only consider rows above the given row\n",
    "above_df = df.iloc[:row_index]\n",
    "\n",
    "# if len(above_df) == 0:\n",
    "#     return pd.DataFrame()\n",
    "\n",
    "\n",
    "# select the A and B columns of the DataFrame\n",
    "df_ab = above_df[['A', 'B']]\n",
    "\n",
    "# calculate the Euclidean distance between the given row and all other rows based on A and B values\n",
    "distances = distance.cdist(df_ab, [given_row[['A', 'B']]], metric='euclidean')\n",
    "\n",
    "# get the indices of rows sorted by distance\n",
    "sorted_indices = distances.argsort(axis=0).flatten()\n",
    "\n",
    "# select the two closest rows (excluding the given row itself)\n",
    "closest_indices = sorted_indices[0:3]\n",
    "\n",
    "# get the closest rows as a DataFrame\n",
    "closest_rows = df.iloc[closest_indices]\n",
    "\n",
    "print(closest_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204bbfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Generate a sample DataFrame\n",
    "df = pd.DataFrame({'A': [1, 1, 1, 4, 1],\n",
    "                   'B': [6, 2, 2, 9, 2],\n",
    "                   'C': [11, 3, 3, 14, 3]})\n",
    "\n",
    "# Define a function to find the two closest rows above a given row based on A and B values\n",
    "def find_closest_rows_above(df, row):\n",
    "    # Find the index of the given row\n",
    "    row_index = df.index.get_loc(row.name)\n",
    "    \n",
    "    # Slice the DataFrame to only consider rows above the given row\n",
    "    above_df = df.iloc[:row_index]\n",
    "    \n",
    "    if len(above_df) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Compute the distances between the given row and all rows above it in the DataFrame based on A and B values\n",
    "    distances = cdist(above_df[['A', 'B']].values, row[['A', 'B']].values.reshape(1, -1))\n",
    "    \n",
    "    # Sort the distances in ascending order and retrieve the index of the closest row\n",
    "    closest_index = distances.argmin(axis=0)[0]\n",
    "    \n",
    "    # Use the index to retrieve the closest row from the DataFrame\n",
    "    closest_row = above_df.iloc[closest_index]\n",
    "    \n",
    "    # Find the index of the second closest row\n",
    "    second_closest_index = (distances != distances[closest_index]).argmax(axis=0)[0]\n",
    "    \n",
    "    # Use the index to retrieve the second closest row from the DataFrame\n",
    "    second_closest_row = above_df.iloc[second_closest_index]\n",
    "    \n",
    "    return pd.concat([closest_row, second_closest_row], axis=1).T\n",
    "\n",
    "# Define a sample row to search for\n",
    "search_row = df.iloc[2] \n",
    "# For i in range(0, len(df)): \n",
    "#     search_row = df.iloc[i]\n",
    "# Append the closest_rows to a new dataframe and then glue the 2 dataframes together at the end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find the two closest rows above the search row based on A and B values\n",
    "closest_rows = find_closest_rows_above(df, search_row)\n",
    "\n",
    "print(closest_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab254b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a DataFrame\n",
    "df = pd.DataFrame({'pos1': [25, 30, 35],\n",
    "                   'pos2': [25, 30, 35],\n",
    "                   'pos3': [25, 30, 35]})\n",
    "\n",
    "# create a new DataFrame with the new columns\n",
    "closest_rows = pd.DataFrame({'pos1DIFF': [50000, 60000, 70000],\n",
    "                         'pos2DIFF': [1, 2, 3]})\n",
    "\n",
    "# concatenate the new DataFrame to the existing one\n",
    "result = pd.concat([df, closest_rows], axis=1)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in df_normal:\n",
    "    X.append(np.asarray(df_normal[0].iloc[0:10,2:]))\n",
    "    y.append(np.asarray(df_normal[0].iloc[10,2:]))\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "np.save(r'C:\\Users\\aidan\\Desktop\\School\\5G_Networks\\Final_Project\\{}\\X.npy'.format(start_folder), X)\n",
    "np.save(r'C:\\Users\\aidan\\Desktop\\School\\5G_Networks\\Final_Project\\{}\\y.npy'.format(start_folder), y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
